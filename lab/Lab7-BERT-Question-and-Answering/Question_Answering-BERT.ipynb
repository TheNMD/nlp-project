{"cells":[{"cell_type":"markdown","metadata":{"id":"mPEAbooer2JN"},"source":["To perform this task, we will use the pretrain model from the **transformer** package. We can install it through the following command."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10844,"status":"ok","timestamp":1674948133402,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"RRIs1xe4xp4Q","outputId":"65841b2a-854e-492b-e1d6-252826177708"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"k9RT4gZbsHP0"},"source":["Import the necessary libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"kGnLGj-vwU9t"},"outputs":[],"source":["from transformers import BertTokenizer\n","from transformers import BertForQuestionAnswering\n","import torch"]},{"cell_type":"markdown","metadata":{"id":"tW2ul9e-4kQw"},"source":["### We use the pretrained BertForQuestionAnswering model 'bert-large-uncased-whole-word-masking-finetuned-squad', more information here: https://huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKwxqnqHx3Na"},"outputs":[],"source":["# Initialize tokenizer for corpus of bert-large-uncased\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n","\n","# Initialize model BertForQuestionAnswering for bert-large-uncased\n","model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad', return_dict=False)"]},{"cell_type":"markdown","metadata":{"id":"aKMF737osow7"},"source":["Define the main function:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yKo_OxxyAHe"},"outputs":[],"source":["def answer_question(question, answer_text):\n","    '''\n","    Lấy input là chuỗi string của câu question và answer_text chứa nội dung câu trả lời của câu question.\n","    Xác định từ trong answer_text là câu trả lời và in ra.\n","    '''\n","    # ======== Tokenize ========\n","    # Áp dụng tokenizer cho cặp câu <question, answer_text>. input_ids là concatenate indice của cả 2 câu sau khi đã thêm các token CLS và SEP như mô tả trong tác vụ Question and Answering.\n","    input_ids = tokenizer.encode(question, answer_text)\n","\n","    # ======== Set Segment IDs ========\n","    # Xác định vị trí đầu tiên chứa token [SEP] trong câu.\n","    sep_index = input_ids.index(tokenizer.sep_token_id)\n","\n","    # Tạo segment index đánh dấu các vị trí từ thuộc question (giá trị 0) và answer_text (giá trị 1)\n","    num_seg_a = sep_index + 1\n","    num_seg_b = len(input_ids) - num_seg_a\n","    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n","\n","    # Kiểm tra độ dài segment_ids phải bằng input_ids\n","    assert len(segment_ids) == len(input_ids)\n","\n","    # ======== Evaluate ========\n","    # Dự báo phân phối xác suất của vị trí của từ start và từ end trong chuỗi concatenate <question, answer_text> mà chứa kết quả cho câu trả lời.\n","    start_scores, end_scores = model(torch.tensor([input_ids]), # chuỗi index biểu thị cho inputs.\n","                                    token_type_ids=torch.tensor([segment_ids])) # chuỗi index thành phần segment câu để phân biệt giữa câu question và câu answer_text\n","\n","    # ======== Reconstruct Answer ========\n","    # Tìm ra vị trí start, end với score là cao nhất\n","    answer_start = torch.argmax(start_scores)\n","    answer_end = torch.argmax(end_scores)\n","\n","    # Chuyển ngược từ input_ids sang list tokens\n","    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","\n","    # Token đầu tiên của câu trả lời\n","    answer = tokens[answer_start]\n","\n","    # Lựa chọn các thành phần còn lại của câu trả lời và join chúng với whitespace.\n","    for i in range(answer_start + 1, answer_end + 1):\n","        \n","        # Nếu token là một subword token (có dấu ## ở đầu) thì combine vào answer bằng token gốc (loại bỏ dấu ##).\n","        if tokens[i][0:2] == '##':\n","            answer += tokens[i][2:]\n","        \n","        # Nếu trái lại thì combine trực tiếp vào answer.\n","        else:\n","            answer += ' ' + tokens[i]\n","    print('Question: \"' + question + '\"')\n","    print('Answer: \"' + answer + '\"')"]},{"cell_type":"markdown","metadata":{"id":"ST2kbCQKtJk6"},"source":["Test the model on a few pairs of Question - Paragraph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":695,"status":"ok","timestamp":1674948655401,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"Z7z2szHRwU9z","outputId":"c7a564f4-a56b-4b08-aa3d-b6e0976bda40","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: \"what is my dog name?\"\n","Answer: \"ricky\"\n"]}],"source":["question = \"what is my dog name?\"\n","paragraph = \"I have a dog. It's name is Ricky. I get it at my 15th birthday, when it was a puppy.\"\n","\n","answer_question(question, paragraph)"]},{"cell_type":"markdown","metadata":{"id":"97Zzxn7luMti"},"source":["Test another longer text."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1491,"status":"ok","timestamp":1674948713026,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"D7U6TJVNwU90","outputId":"3285d2e4-8d44-4ba6-dae2-7e2575da98fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: \"when Leonhard Euler was born?\"\n","Answer: \"15 april 1707\"\n"]}],"source":["question = \"when Leonhard Euler was born?\"\n","paragraph = \"Leonhard Euler: 15 April 1707 – 18 September 1783 was a Swiss mathematician, \\\n","physicist, astronomer, geographer, logician and engineer who made important and influential discoveries in many branches of mathematics, \\\n","such as infinitesimal calculus and graph theory, \\\n","while also making pioneering contributions to several branches such as topology and analytic number theory. \\\n","He also introduced much of the modern mathematical terminology and notation, \\\n","particularly for mathematical analysis, such as the notion of a mathematical function.[4] He is also known for his work in mechanics, fluid dynamics, optics, astronomy and music theory\"\n","\n","answer_question(question, paragraph)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1435,"status":"ok","timestamp":1674949147261,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"vs1P4t5TvjDY","outputId":"1c4b5216-612c-4cfa-fa08-594f56f9ca51"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: \"what is Picasso's father job\"\n","Answer: \"a painter\"\n"]}],"source":["paragraph = \"Picasso was born at 23:15 on 25 October 1881, in the city of Málaga, Andalusia, in southern Spain. \\\n","He was the first child of Don José Ruiz y Blasco (1838–1913) and María Picasso y López. Picasso's family was of middle-class background. \\\n","His father was a painter who specialized in naturalistic depictions of birds and other game. For most of his life, Ruiz was a professor of art at the School of Crafts and a curator of a local museum. \\\n","Ruiz's ancestors were minor aristocrats.\"\n","\n","question = \"what is Picasso's father job\"\n","answer_question(question, paragraph)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2014,"status":"ok","timestamp":1674949240926,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"LsNf8OJ-wRPY","outputId":"7b5a9736-fc15-4b20-e7a5-c7ac66144eb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: \"what is the occupation of Picasso's father\"\n","Answer: \"painter\"\n"]}],"source":["question = \"what is the occupation of Picasso's father\"\n","answer_question(question, paragraph)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2961,"status":"ok","timestamp":1674949287154,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"yK694qJowVPo","outputId":"8a5205b1-904b-40ea-bc46-54e3ccf8b92a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: \"what is his mother's name\"\n","Answer: \"maria picasso y lopez\"\n"]}],"source":["question = \"what is his mother's name\"\n","answer_question(question, paragraph)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1671,"status":"ok","timestamp":1674949354501,"user":{"displayName":"huynh khai","userId":"16623457394309231198"},"user_tz":-420},"id":"HqnkwnhvwjTg","outputId":"d7355233-e68a-4b58-9317-a3b34448a48a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: \"what is Picasso's family like\"\n","Answer: \"middle - class background\"\n"]}],"source":["question = \"what is Picasso's family like\"\n","answer_question(question, paragraph)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1srU5584QF_d3NCE9UX9q-6ZgxUTo6FBt","timestamp":1633867144346},{"file_id":"1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ","timestamp":1616587562665}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
