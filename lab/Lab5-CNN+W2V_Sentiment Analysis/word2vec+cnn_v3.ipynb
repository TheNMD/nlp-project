{"cells":[{"cell_type":"code","execution_count":123,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4639,"status":"ok","timestamp":1653989252196,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"aoVjFKmOZMZ8","outputId":"bcd119ff-e091-4cf5-ca96-45e131211e1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyvi in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (0.1.1)\n","Requirement already satisfied: scikit-learn in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from pyvi) (1.3.2)\n","Requirement already satisfied: sklearn-crfsuite in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from pyvi) (0.3.6)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from scikit-learn->pyvi) (1.26.2)\n","Requirement already satisfied: scipy>=1.5.0 in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from scikit-learn->pyvi) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from scikit-learn->pyvi) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from scikit-learn->pyvi) (3.2.0)\n","Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.9.9)\n","Requirement already satisfied: six in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n","Requirement already satisfied: tabulate in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from sklearn-crfsuite->pyvi) (4.66.1)\n","Requirement already satisfied: colorama in c:\\users\\asus\\downloads\\coding\\school\\nlp-project\\venv\\lib\\site-packages (from tqdm>=2.0->sklearn-crfsuite->pyvi) (0.4.6)\n"]}],"source":["!pip install pyvi"]},{"cell_type":"code","execution_count":124,"metadata":{"id":"8TFX7wSAmg9y"},"outputs":[],"source":["import pandas as pd \n","import numpy as np\n","from string import digits\n","from pyvi import ViTokenizer\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","%matplotlib inline"]},{"cell_type":"code","execution_count":151,"metadata":{"id":"a7lMy03omg93","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data\n","    Class                                               Data\n","0     -1  Mình đã dùng anywhere thế hệ đầu, quả là đầy t...\n","1     -1  Quan tâm nhất là độ trễ có cao không, dùng thi...\n","2     -1  dag xài con cùi bắp 98k....pin trâu, mỗi tội đ...\n","3     -1  logitech chắc hàng phải tiền triệu trở lên dùn...\n","4     -1  Đang xài con m175 cùi mía , nhà xài nhiều chuộ...\n","Testing data\n","    Class                                               Data\n","0     -1  Nói thiệt là mình thì thì chuột nào mình cũng ...\n","1     -1  Đang dùng mx1. Cũng ngon nhưng chưa đầy năm mà...\n","2     -1  Chưa thấy đc điểm thuyết phục để mua, nhất là ...\n","3     -1  Những phần xem báo tra cứu bản đồ, dịch vụ.. d...\n","4     -1  ĐÚNG LÀ MUA Ở VIỆT NAM KHÔNG ỨNG DỤNG ĐƯỢC GÌ ...\n"]}],"source":["# Load train and test data from csv files\n","data_train = pd.read_csv(\"vlsp_sentiment_train.csv\", sep='\\t')\n","data_train.columns =['Class', 'Data']\n","train_labels = data_train.iloc[:, 0].values\n","train_texts = data_train.iloc[:, 1].values\n","print(\"Training data\\n\", data_train.head(5))\n","\n","data_test = pd.read_csv(\"vlsp_sentiment_test.csv\", sep='\\t')\n","data_test.columns =['Class', 'Data']\n","test_labels = data_test.iloc[:, 0].values\n","test_texts = data_test.iloc[:, 1].values\n","print(\"Testing data\\n\", data_test.head(5))"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1653989301990,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"4HR1jAzImg94","outputId":"8e324c8c-0dbb-4a69-aeff-b03e40766c7e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5100, 2)\n","(1050, 2)\n"]}],"source":["print(data_train.shape)\n","print(data_test.shape)"]},{"cell_type":"code","execution_count":127,"metadata":{"id":"jvrbwPfZmg95"},"outputs":[],"source":["labels = data_train.iloc[:, 0].values\n","reviews = data_train.iloc[:, 1].values"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[],"source":["# Encoding labels\n","# -1 = Negative = [1,0,0]\n","#  0 = Neutral   = [0,1,0]\n","#  1 = Positive = [0,0,1]\n","def encoding_labels(labels):\n","    encoded_labels = []\n","    for label in labels:\n","        if label == -1:\n","            encoded_labels += [[1, 0, 0]]\n","        elif label == 0:\n","            encoded_labels += [[0, 1, 0]]\n","        else:\n","            encoded_labels += [[0 ,0, 1]]\n","    return np.array(encoded_labels)"]},{"cell_type":"code","execution_count":133,"metadata":{"id":"Lm4OCwxXmg96"},"outputs":[],"source":["EMBEDDING_DIM = 400 # how big is each word vector\n","MAX_VOCAB_SIZE = 10000 # how many unique words to use (i.e num rows in embedding vector)\n","MAX_SEQUENCE_LENGTH = 300 # max number of words in a comment to use\n","\n","texts_processed = []\n","for review in train_texts:\n","    text_cool_one = ''.join([char for char in review if char not in digits])\n","    texts_processed.append(text_cool_one)\n","    \n","texts_tokenized = []\n","for review in texts_processed:\n","    review = ViTokenizer.tokenize(review.lower())\n","    texts_tokenized.append(review.split())\n","\n","tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n","tokenizer.fit_on_texts(texts_tokenized)\n","sequences_train = tokenizer.texts_to_sequences(texts_tokenized)\n","word_index = tokenizer.word_index\n","\n","X_train = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n","y_train = encoding_labels(train_labels)"]},{"cell_type":"code","execution_count":134,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653989306259,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"4dl9VZ3Rmg-A","outputId":"0d43e170-e903-4d5b-f3ec-18a8b911d072"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X train and X validation tensor: (5100, 300)\n","Shape of label train and validation tensor: (5100, 3)\n"]}],"source":["print('Shape of X train and X validation tensor:', X_train.shape)\n","print('Shape of label train and validation tensor:', y_train.shape)"]},{"cell_type":"code","execution_count":135,"metadata":{"id":"-KKSjJdJmg-A"},"outputs":[],"source":["from gensim.models.keyedvectors import KeyedVectors\n","\n","word_vectors = KeyedVectors.load_word2vec_format(fname='./vi-model-CBOW.bin', binary=True)\n","\n","vocabulary_size=min(len(word_index)+1,MAX_VOCAB_SIZE)\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i>=MAX_VOCAB_SIZE:\n","        continue\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del(word_vectors)\n","\n","from keras.layers import Embedding\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=True)"]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[],"source":["from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, concatenate, Flatten, Reshape, Dropout, Dense\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1653989417080,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"njBANdn5mg-B","outputId":"24647910-9144-4987-83a2-fe64e64a04ac"},"outputs":[{"ename":"NameError","evalue":"name 'Input' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\ASUS\\Downloads\\Coding\\School\\nlp-project\\lab\\Lab5-CNN+W2V_Sentiment Analysis\\word2vec+cnn_v3.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m EPSILON \u001b[39m=\u001b[39m \u001b[39m1e-08\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Define the CNN model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m input_layer \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(SEQUENCE_LENGTH,))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m embedding_layer \u001b[39m=\u001b[39m Embedding(input_dim\u001b[39m=\u001b[39mvocabulary_size, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                             output_dim\u001b[39m=\u001b[39mEMBEDDING_DIM, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                             weights\u001b[39m=\u001b[39m[embedding_matrix], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                             trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(input_layer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m conv_layer_0 \u001b[39m=\u001b[39m Conv1D(NUM_FILTERS, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                       FILTER_SIZES[\u001b[39m0\u001b[39m], \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                       activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASUS/Downloads/Coding/School/nlp-project/lab/Lab5-CNN%2BW2V_Sentiment%20Analysis/word2vec%2Bcnn_v3.ipynb#X13sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                       kernel_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39ml2(REGULIZERS_LAMBDA))(embedding_layer)\n","\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"]}],"source":["# CNN hyperparameters\n","SEQUENCE_LENGTH = 300\n","FILTER_SIZES = [3, 4, 5]\n","NUM_FILTERS = 100\n","DROP_RATE = 0.5\n","REGULIZERS_LAMBDA = 0.01\n","\n","# Optimizer hyperparameters\n","LEARNING_RATE = 0.001\n","BETA_1 = 0.9\n","BETA_2 = 0.999\n","EPSILON = 1e-08\n","\n","# Define the CNN model\n","input_layer = Input(shape=(SEQUENCE_LENGTH,))\n","\n","embedding_layer = Embedding(input_dim=vocabulary_size, \n","                            output_dim=EMBEDDING_DIM, \n","                            weights=[embedding_matrix], \n","                            trainable=True)(input_layer)\n","\n","conv_layer_0 = Conv1D(NUM_FILTERS, \n","                      FILTER_SIZES[0], \n","                      activation='relu', \n","                      kernel_regularizer=regularizers.l2(REGULIZERS_LAMBDA))(embedding_layer)\n","conv_layer_1 = Conv1D(NUM_FILTERS, \n","                      FILTER_SIZES[1], \n","                      activation='relu', \n","                      kernel_regularizer=regularizers.l2(REGULIZERS_LAMBDA))(embedding_layer)\n","conv_layer_2 = Conv1D(NUM_FILTERS, \n","                      FILTER_SIZES[2], \n","                      activation='relu', \n","                      kernel_regularizer=regularizers.l2(REGULIZERS_LAMBDA))(embedding_layer)\n","\n","maxpool_layer_0 = MaxPooling1D(SEQUENCE_LENGTH - FILTER_SIZES[0] + 1, strides=1)(conv_layer_0)\n","maxpool_layer_1 = MaxPooling1D(SEQUENCE_LENGTH - FILTER_SIZES[1] + 1, strides=1)(conv_layer_1)\n","maxpool_layer_2 = MaxPooling1D(SEQUENCE_LENGTH - FILTER_SIZES[2] + 1, strides=1)(conv_layer_2)\n","\n","merged_tensor = concatenate([maxpool_layer_0, maxpool_layer_1, maxpool_layer_2], axis=1)\n","flatten = Flatten()(merged_tensor)\n","reshape = Reshape((3 * NUM_FILTERS,))(flatten)\n","dropout = Dropout(DROP_RATE)(flatten)\n","output_layer = Dense(units=3, activation='softmax', kernel_regularizer=regularizers.l2(REGULIZERS_LAMBDA))(dropout)\n","\n","\n","model = Model(input_layer, output_layer)\n","\n","model.compile(loss='categorical_crossentropy', \n","              optimizer=Adam(learning_rate=LEARNING_RATE, beta_1=BETA_1, beta_2=BETA_2, epsilon=EPSILON), \n","              metrics=['accuracy'])\n","\n","print(model.summary())\n","\n","# Early stopping hyperparameters\n","MIN_DELTA = 0.01 \n","PATIENCE = 4\n","\n","# Define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=MIN_DELTA, patience=PATIENCE, verbose=1)\n","csv_logger = CSVLogger('CNN_log.csv', append=False, separator=';')\n","checkpoint = ModelCheckpoint('CNN_checkpoint.keras', \n","                              save_best_only=False, \n","                              verbose=0)\n","callbacks_list = [early_stopping, csv_logger, checkpoint]"]},{"cell_type":"code","execution_count":141,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10375,"status":"ok","timestamp":1653989547863,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"Jn0dBlzjmg-D","outputId":"be7de957-bf78-4fff-bc31-b5e586f705fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","16/16 [==============================] - 10s 584ms/step - loss: 7.9197 - accuracy: 0.4348 - val_loss: 11.2040 - val_accuracy: 0.0039\n","Epoch 2/5\n","16/16 [==============================] - 9s 569ms/step - loss: 5.6155 - accuracy: 0.6167 - val_loss: 7.4101 - val_accuracy: 0.0304\n","Epoch 3/5\n","16/16 [==============================] - 9s 597ms/step - loss: 4.6745 - accuracy: 0.7113 - val_loss: 6.1083 - val_accuracy: 0.1333\n","Epoch 4/5\n","16/16 [==============================] - 9s 569ms/step - loss: 4.0475 - accuracy: 0.7814 - val_loss: 5.3298 - val_accuracy: 0.1804\n","Epoch 5/5\n","16/16 [==============================] - 9s 573ms/step - loss: 3.5430 - accuracy: 0.8275 - val_loss: 5.1105 - val_accuracy: 0.1500\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x154f408e530>"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_train, y_train, validation_split=0.2,\n","          epochs=5, batch_size=256, callbacks=callbacks_list, shuffle=True)"]},{"cell_type":"code","execution_count":168,"metadata":{"id":"8XoN2UOamg-D"},"outputs":[],"source":["reviews_test = data_test.iloc[:, 1].values\n","\n","texts_processed = []\n","for review_test in reviews_test:\n","    text_cool_one = ''.join([char for char in review_test if char not in digits])\n","    texts_processed.append(text_cool_one)\n","    \n","#Use PyVi for Vietnamese word tokenizer\n","word_reviews_test = []\n","all_words = []\n","for review in texts_processed:\n","    review = ViTokenizer.tokenize(review.lower())\n","    word_reviews_test.append(review.split())\n","    \n","sequences_test = tokenizer.texts_to_sequences(word_reviews_test)\n","\n","X_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n","y_test = encoding_labels(test_labels)  "]},{"cell_type":"code","execution_count":170,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1653989548454,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"},"user_tz":-420},"id":"LKclttiOmg-F","outputId":"6abe8e2e-7ed4-439f-8899-e6b30a044758"},"outputs":[{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 0s 15ms/step - loss: 3.9320 - accuracy: 0.5771\n","loss: 3.93%\n","accuracy: 57.71%\n"]}],"source":["score = model.evaluate(X_test, y_test)\n","\n","print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]))\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n"]}],"metadata":{"accelerator":"GPU","colab":{"name":"word2vec+cnn_v3.ipynb","provenance":[{"file_id":"1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ","timestamp":1653989613942}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
